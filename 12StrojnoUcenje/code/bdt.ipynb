{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "plt.style.use(r'customStyle')\n",
    "\n",
    "# data processing\n",
    "import loader as load\n",
    "\n",
    "# #import the working methods\n",
    "# import tensorflow as tf\n",
    "# print(\"TensorFlow version \",tf.__version__)\n",
    "\n",
    "# from tensorflow import keras\n",
    "\n",
    "\n",
    "# from tensorflow.keras import Sequential,Model\n",
    "# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- globals\n",
    "\n",
    "# Need to see a large portion of the data before we can build a layer, for\n",
    "# example half of data n_batches_per_layer =  NBATCH_FRAC * NUM_EXAMPLES / BATCH_SIZE\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "SEED_VALUE= 10001\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(SEED_VALUE)\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(SEED_VALUE)\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/higgs-parsed.h5...\n",
      "Loaded.\n",
      "Entries read 18 with feature names ['lepton-pT' 'lepton-eta' 'missing-energy' 'jet_1-pt' 'jet_1-eta'\n",
      " 'jet_2-pt' 'jet_2-eta' 'jet_3-pt' 'jet_3-eta' 'jet_4-pt' 'jet_4-eta'\n",
      " 'm_jj' 'm_jjj' 'm_lv' 'm_jlv' 'm_bb' 'm_wbb' 'm_wwbb']\n",
      "x_train shape:  (360000, 18)\n",
      "x_test shape:  (40000, 18)\n",
      "x_val shape:  (100000, 18)\n",
      "Decision Tree AUC: 0.7409\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = r\"data/higgs-parsed.h5\"\n",
    "\n",
    "hdata = load.load_data_from_path(DATA_PATH)\n",
    "data_fnames = hdata['feature_names'].to_numpy()[1:]\n",
    "n_dims = data_fnames.shape[0]\n",
    "print(\"Entries read {} with feature names {}\".format(n_dims, data_fnames))\n",
    "\n",
    "def split_xy_noscale(df):\n",
    "    y = df['hlabel']\n",
    "    X = df.drop(['hlabel'], axis=1) \n",
    "    return X, y\n",
    "\n",
    "x_trn_raw, y_trn = split_xy_noscale(hdata['train'])\n",
    "x_train_raw, x_test_raw, y_train, y_test = train_test_split(\n",
    "    x_trn_raw, y_trn, test_size=0.1, stratify=y_trn, random_state=42\n",
    ")\n",
    "x_val_raw, y_val = split_xy_noscale(hdata['valid'])\n",
    "\n",
    "scaler = MinMaxScaler().fit(x_train_raw)\n",
    "\n",
    "def _tf(scaler, X):\n",
    "    Xt = scaler.transform(X)\n",
    "    return pd.DataFrame(Xt, columns=X.columns, index=X.index)\n",
    "\n",
    "x_train = _tf(scaler, x_train_raw)\n",
    "x_test  = _tf(scaler, x_test_raw)\n",
    "x_val   = _tf(scaler, x_val_raw)\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"x_val shape: \", x_val.shape)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=SEED_VALUE)\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict_proba(x_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"Decision Tree AUC: {:.4f}\".format(auc))\n",
    "# 0.7409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/higgs-parsed.h5...\n",
      "Loaded.\n",
      "Entries read 18 with feature names ['lepton-pT' 'lepton-eta' 'missing-energy' 'jet_1-pt' 'jet_1-eta'\n",
      " 'jet_2-pt' 'jet_2-eta' 'jet_3-pt' 'jet_3-eta' 'jet_4-pt' 'jet_4-eta'\n",
      " 'm_jj' 'm_jjj' 'm_lv' 'm_jlv' 'm_bb' 'm_wbb' 'm_wwbb']\n",
      "x_train shape:  (360000, 18)\n",
      "x_test shape:  (40000, 18)\n",
      "x_val shape:  (100000, 18)\n",
      "CatBoost AUC: 0.8194\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = r\"data/higgs-parsed.h5\"\n",
    "\n",
    "hdata = load.load_data_from_path(DATA_PATH)\n",
    "data_fnames = hdata['feature_names'].to_numpy()[1:]\n",
    "n_dims = data_fnames.shape[0]\n",
    "print(\"Entries read {} with feature names {}\".format(n_dims, data_fnames))\n",
    "\n",
    "def split_xy_noscale(df):\n",
    "    y = df['hlabel']                       # labels: 0=bkg, 1=sig\n",
    "    X = df.drop(['hlabel'], axis=1)        # features\n",
    "    return X, y\n",
    "\n",
    "x_trn_raw, y_trn = split_xy_noscale(hdata['train'])\n",
    "x_train_raw, x_test_raw, y_train, y_test = train_test_split(\n",
    "    x_trn_raw, y_trn, test_size=0.1, stratify=y_trn, random_state=42\n",
    ")\n",
    "x_val_raw, y_val = split_xy_noscale(hdata['valid'])\n",
    "\n",
    "scaler = MinMaxScaler().fit(x_train_raw)\n",
    "\n",
    "def _tf(scaler, X):\n",
    "    Xt = scaler.transform(X)\n",
    "    return pd.DataFrame(Xt, columns=X.columns, index=X.index)\n",
    "\n",
    "x_train = _tf(scaler, x_train_raw)\n",
    "x_test  = _tf(scaler, x_test_raw)\n",
    "x_val   = _tf(scaler, x_val_raw)\n",
    "\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"x_val shape: \", x_val.shape)\n",
    "\n",
    "bdt = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    eval_metric='AUC',\n",
    "    random_seed=SEED_VALUE,\n",
    "    logging_level='Silent',\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "train_pool = Pool(x_train, y_train)\n",
    "val_pool = Pool(x_val, y_val)\n",
    "bdt.fit(train_pool, eval_set=val_pool, verbose=100)\n",
    "y_pred = bdt.predict_proba(x_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"CatBoost AUC: {:.4f}\".format(auc))\n",
    "# 0.8194"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
